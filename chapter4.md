# [第 4 章：Web SVG 数据工程：采集、清洗、规范化与对齐](chapter4.md)

## 1. 开篇段落

在多模态大模型（MLLM）的训练中，数据不仅决定了模型能力的上限，更决定了模型的“思维方式”。对于 SVG 这种特殊的模态——它既是**视觉图像**，又是**代码文本**（XML）——数据工程的复杂度远超纯文本或纯像素图像。

互联网（Common Crawl, GitHub, Icon Repositories）是最大的 SVG 矿藏，但它同时也是一个充斥着冗余代码、无效引用和非标准语法的沼泽。一个视觉上是圆形的图案，在 SVG 源码中可能被写作 `<circle>`，也可能是 `<path>`，甚至可能是一个应用了极坐标变换的 `<rect>`。如果你直接将原始 Web SVG 喂给模型，模型将不得不浪费大量参数去记忆 XML 的千奇百怪的写法，而不是学习图形的几何本质。

本章将带你构建一条完整的 **ETL（Extract, Transform, Load）流水线**。我们将深入探讨如何从 HTML 废墟中挖掘 SVG，如何通过**规范化（Canonicalization）**将 SVG 的“熵”降到最低，如何处理复杂的 CSS 依赖，以及如何利用现有的 VLM（视觉大模型）生成高质量的**合成文本对齐数据**。完成本章后，你将拥有构建一个百万级高质量 SVG-Text 配对数据集的能力。

---

## 2. 核心论述

### 2.1 数据源与采集策略：SVG 的三种“栖息形态”

网页中的 SVG 并非总是以 `.svg` 文件的形式存在。为了最大化数据量，我们需要针对三种形态制定不同的采集策略：

#### A. 独立文件（External Files）
这是最容易采集的形式，通常通过 `<img src="icon.svg">` 或 `<object data="graph.svg">` 引用。
*   **优点**：结构通常是完整的 XML 文档，自带 `<?xml ...?>` 头。
*   **缺点**：严重缺乏上下文。文件名可能是唯一的文本线索（如 `asset_42.svg`，毫无意义）。
*   **策略**：爬取时必须同时保存引用该文件的 `alt` 属性、周边 `<caption>` 或父级 `<div>` 的文本，作为元数据。

#### B. 内联 SVG（Inline SVG）
直接嵌入在 HTML DOM 树中的 `<svg>...</svg>` 代码块。
*   **优点**：拥有最丰富的上下文（网页标题、段落文本）。
*   **缺点**：**污染严重**。通常充斥着大量的 `class="css-xyz"`，且高度依赖外部 CSS 渲染颜色。
*   **策略**：提取时需连带解析计算后的 CSS 样式（Computed Styles），将其固化为行内属性（例如将 `.cls-1 { fill: red }` 转换为 `fill="red"`），否则提取出的 SVG 往往是一片漆黑。

#### C. 图标精灵与符号系统（Sprites & Symbol Systems）
这是现代前端开发的常见模式。一个 SVG 文件作为一个“容器”，内部包含数十个 `<symbol id="icon-user">`，页面通过 `<use xlink:href="#icon-user">` 来显示。
*   **优点**：**数据密度极高**，通常是经过专业设计师优化的图标，拓扑结构极其规范。
*   **挑战**：需要编写专门的“解包器（Unpacker）”。
*   **策略**：将每个 `<symbol>` 提取出来，包裹上 `<svg>` 根标签，并将原容器 `<defs>` 中的公共资源（如渐变、滤镜）复制到新文件中，形成独立的训练样本。

```text
[ 采集难度分级 ]
Easy:   .svg 文件下载
Medium: <symbol> 解包与资源依赖解析
Hard:   Inline SVG 的 CSS 样式计算与属性内联
```

### 2.2 清洗（Sanitization）：剔除“伪 SVG”与风险

并不是所有 `<svg>` 标签里的内容都是我们想要的。在进入模型之前，必须进行严格的清洗。

*   **剔除 Base64 位图（The Raster Trap）**：
    这是 SVG 数据集最大的污染源。很多设计工具导出 SVG 时，如果遇到无法矢量化的特效，会直接截图并在 SVG 里插入 `<image href="data:image/png;base64..." />`。
    *   *Rule-of-Thumb*：解析 XML，计算 `<image>` 标签覆盖的面积。如果 `<image>` 面积超过 ViewBox 的 80%，或者文件体积的 90% 都是 Base64 字符串，直接丢弃。这是“伪 SVG”。

*   **安全清洗**：
    SVG 是 XML，支持脚本。必须移除所有 `<script>` 标签、`onclick`/`onload` 等事件属性。这不仅是为了安全，也是因为生成模型不需要学习交互逻辑。

*   **元数据剥离**：
    移除 `xmlns:inkscape`、`adobe:save-meta` 等编辑器私有数据。移除 `data-*` 属性。移除注释 `<!-- ... -->`。这些不仅消耗 Token，还可能让模型过拟合到特定的编辑器特征上。

### 2.3 规范化（Canonicalization）：降低几何熵

这是本章**最核心**的技术点。规范化的目标是：**对于同样的视觉输出，强制模型只看到一种标准的代码表达。**

#### 1. 视口归一化（ViewBox Normalization）
不同 SVG 的坐标系千差万别。有的 ViewBox 是 `0 0 24 24`，有的是 `0 0 1024 768`，有的是 `-50 -50 100 100`。
*   **操作**：将所有 SVG 的坐标重映射到一个标准化的正方形空间（例如 `0 0 256 256`）。
*   **保留纵横比**：如果原图是长方形，保持长边为 256，短边居中，通过 `padding` 填充。

#### 2. 变换扁平化（Transform Flattening / Baking）
SVG 允许在 Group (`<g>`) 或 Path 上应用 `transform="translate(x,y) rotate(a) scale(s)"`。这对模型理解几何极其不友好（模型需要在大脑中进行矩阵乘法才能知道线条真正画在哪里）。
*   **操作**：遍历 DOM 树，将所有父级节点的变换矩阵**累乘**，并应用到叶子节点（Path）的每一个控制点坐标上。最后移除所有 `transform` 属性。
*   **结果**：模型看到的坐标就是最终渲染的屏幕坐标。

#### 3. 图元统一化（Primitive to Path）
SVG 有 `<rect>`, `<circle>`, `<ellipse>`, `<line>`, `<polyline>`, `<polygon>` 等基础形状。
*   **操作**：全部转换为 `<path d="...">`。
*   **理由**：将词表（Vocabulary）压缩到极致。模型只需要学会 M, L, C, Z 等路径指令，而不需要单独学习“矩形”的概念（矩形只是 Path 的一种特例）。

#### 4. 数值精度截断
SVG 编辑器经常生成 `10.0000000001` 这样的坐标。
*   **操作**：保留 1 位或 2 位小数（例如 `10.0`），甚至在 256x256 的尺度下直接取整。这能显著减少 Token 长度，且肉眼几乎不可见差异。

### 2.4 结构化表示与 Tokenization 预备

在文本层面，SVG 是一长串字符。但在模型眼中，它应该是一串**结构化的 Token**。

*   **命令与参数分离**：
    原始：`M10 20L30 40`
    处理后：`<M> <10> <20> <L> <30> <40>`
    建议在清洗阶段就在数字和命令之间插入空格，方便 BPE（Byte Pair Encoding）分词器处理。

*   **相对坐标 vs 绝对坐标**：
    *   *绝对坐标（M, L, C）*：每个点都是画布上的真实位置。**推荐用于生成模型**，因为具有全局位置感知能力，不容易“画飞”。
    *   *相对坐标（m, l, c）*：每个点是相对于前一个点的偏移。适合压缩，但容易累积误差。
    *   *建议*：在规范化阶段，统一转换为**绝对坐标**。

### 2.5 文本对齐（Alignment）：如何让模型“看懂”图

有了干净的 SVG 代码，我们还需要配对的文本（Prompt）。Web 数据的天然文本质量极差，我们需要多层次的对齐策略：

| 来源 | 质量 | 数量 | 描述 |
| :--- | :--- | :--- | :--- |
| **Alt / Title** | 低 | 极大 | 只有关键词，如 "search icon"。适合做 Keyword-to-SVG。 |
| **Surrounding Text** | 中 | 大 | 网页正文。噪音大，需用 NLP 提取关键词。 |
| **OCR / Detection** | 高 | 中 | 对 SVG 渲染图运行 OCR，提取图中的文字，作为文本提示的一部分。 |
| **合成数据 (Synthetic)** | **极高** | 需计算成本 | **这是 SOTA 的关键。** |

**合成数据流水线（The Synthetic Pipeline）：**
1.  使用渲染引擎（resvg）将清洗后的 SVG 渲染为 PNG。
2.  将 PNG 输入给 GPT-4V / Gemini Pro Vision / Claude 3.5 Sonnet。
3.  Prompt 设计：
    *   "描述这个图标的视觉外观、几何形状和颜色。" (Captioning)
    *   "这段 SVG 代码对应什么功能？" (Code Understanding)
    *   "将图中的红色圆改为蓝色方块，你会怎么做？" (Editing Instruction)
4.  将 VLM 生成的高质量描述与 SVG 代码配对，作为核心训练数据。

### 2.6 数据集切分与防泄漏（Anti-Leakage）

SVG 数据存在严重的**同源相似性**。一个网站的 50 个图标通常由同一个设计师用同一种风格绘制。

*   **错误的切分**：随机 Shuffle 后切分 Train/Test。
    *   *后果*：Train 集里有“首页图标”，Test 集里有“用户页图标”。两者风格、笔触、代码结构完全一致。模型在 Test 集上分数极高，但实际泛化能力极差。
*   **正确的切分**：**Group by Domain**。
    *   来自 `github.com` 的所有 SVG 都在训练集。
    *   来自 `twitter.com` 的所有 SVG 都在测试集。
    *   这样才能评估模型对“未见过的设计风格”的泛化能力。

---

## 3. 本章小结

*   **ETL 决定成败**：不要低估清洗脚本的重要性。一个处理了 transform flatten 和 CSS injection 的脚本，价值胜过单纯的模型架构调整。
*   **规范化即压缩**：通过 Shape-to-Path 和坐标归一化，我们人为地缩小了假设空间，让模型更容易捕捉图形规律。
*   **合成数据是杠杆**：利用强 VLM 进行 Re-captioning，是从“大量垃圾数据”中提炼“高质量对齐数据”的最有效手段。
*   **拒绝伪矢量**：时刻警惕 Base64 这种“披着 SVG 皮的 JPEG”，它们会破坏生成模型的训练稳定性。

---

## 4. 练习题

### 基础题（热身与巩固）

1.  **[转换逻辑]** 给定一个 SVG `<rect x="10" y="20" width="50" height="30" />`。请写出将其转换为 `<path d="...">` 后的指令序列。
    <details><summary>Hint</summary>M (x) (y) -> H (x+w) -> V (y+h) -> H (x) -> Z。注意起点和方向。</details>

2.  **[坐标归一化]** 一个 SVG 的 `viewBox="0 0 100 50"`。如果我们要将其归一化到 `256 x 256` 的正方形画布中并保持居中，原始坐标 `(50, 25)` 在新画布中的坐标应该是多少？
    <details><summary>Hint</summary>计算缩放比例 s = 256/100 = 2.56。Y 轴需要 padding。新 Y = (256 - 50*2.56)/2 + 25*2.56。</details>

3.  **[数据筛选]** 你编写了一个爬虫，抓到了以下三个 SVG 文件，请判断哪些应该保留，哪些应该丢弃，并说明理由：
    *   A. 文件大小 2KB，包含 5 个 path，无 image 标签。
    *   B. 文件大小 500KB，包含 1 个 image 标签，href 为 base64 编码，无 path。
    *   C. 文件大小 5KB，包含 `<script>alert('xss')</script>` 和正常的图形数据。
    <details><summary>Hint</summary>A 保留。B 丢弃（伪 SVG）。C 清洗后保留。</details>

4.  **[文本处理]** 很多从网页提取的 SVG 文件名是 `icon_v2_final_final.svg`。设计一个简单的正则表达式或逻辑，将其转化为可用的文本标签。
    <details><summary>Hint</summary>去扩展名 -> 替换下划线/横杠为空格 -> 去除 v2/final 等无意义词 -> "icon"。</details>

### 挑战题（深入思考）

5.  **[算法设计]** **Transform Flattening**。给定一个嵌套结构：
    ```xml
    <g transform="translate(10, 10)">
      <g transform="scale(2)">
        <path d="M 0 0 L 10 0" />
      </g>
    </g>
    ```
    请描述如何通过矩阵运算，计算出 path 最终的绝对坐标。
    <details><summary>Hint</summary>构建变换矩阵 M1 (translate), M2 (scale)。总矩阵 M = M1 * M2。对点 (0,0) 和 (10,0) 应用 M。</details>

6.  **[场景分析]** 在处理包含文本的 SVG（`<text>Hello</text>`）时，我们面临一个两难选择：是保留 `<text>` 标签让模型学习排版，还是将其转换为轮廓（Outline/Path）？请分析这两种策略在 MLLM 训练中的优缺点。
    <details><summary>Hint</summary>保留标签：模型能修改文字内容，但渲染一致性难保证（缺字体）。转轮廓：渲染绝对一致，但失去了“修改文字内容”的语义编辑能力。</details>

7.  **[架构思考]** 假设你的资源有限，无法对百万级 SVG 全部跑一遍 GPT-4V 做合成标注。你如何设计一个**主动学习（Active Learning）**策略，挑选出最值得标注的那 10% 数据？
    <details><summary>Hint</summary>多样性采样（聚类中心）+ 复杂度适中（过滤太简单和太复杂的）+ 原始文本缺失最严重的。</details>

---

## 5. 常见陷阱与错误 (Gotchas)

*   **陷阱 1：被忽视的 `defs` 与 `use`**
    *   *现象*：解析 `<path>` 时一切正常，但渲染出来缺少部分图形。
    *   *原因*：很多重复图形定义在 `<defs>` 里，通过 `<use>` 引用。如果不解析 `<use>` 标签并将其展开（Instantiate），你的数据集就是残缺的。
    *   *对策*：必须实现 `use` 节点的递归展开逻辑，将引用的图形实体化到当前位置。

*   **陷阱 2：Wind-rule 的噩梦（Non-zero vs Even-odd）**
    *   *现象*：模型生成的图标在某些区域填充颜色反了，原本该空心的地方实心了。
    *   *原因*：SVG 的 `fill-rule` 属性决定了复杂路径的内部填充逻辑。如果规范化时丢失了这个属性，或者混合了不同 fill-rule 的路径。
    *   *对策*：尽量将所有路径通过几何算法统一转换为 `nonzero` 规则，或者在模型输入中显式包含 `fill-rule` token。

*   **陷阱 3：CSS `currentColor`**
    *   *现象*：图标全是黑色的。
    *   *原因*：许多图标设置 `fill="currentColor"`，这是为了让图标颜色跟随父级文字颜色。在独立提取时，`currentColor` 默认解析为黑。
    *   *对策*：在清洗阶段，将 `currentColor` 替换为一个随机深色或标准黑色，或者保留该 Token 作为一个特殊的可控变量。

*   **陷阱 4：XML 解析器的宽容度**
    *   *现象*：Python 的 XML 库报错崩溃，导致整个 batch 失败。
    *   *原因*：网页 SVG 常包含未闭合标签或非法属性，浏览器能容忍，但严谨的 Parser 不能。
    *   *对策*：使用 `lxml` 的 `recover=True` 模式，或者在使用 Parser 前先用正则进行“脏修复”。对于无法修复的坏文件，直接 `try-catch` 丢弃，**千万不要让脏数据中断数据处理流水线**。
